# Bit√°cora 4

## Alcance

Para el *Checkpoint 4*, el enfoque principal del equipo fue la implementaci√≥n de una funcionalidad innovadora y t√©cnicamente desafiante que excediera los requisitos b√°sicos del proyecto.

### Historias (Features Adicional)

*   [x] **Servicio de Generaci√≥n de Covers con IA**: Implementaci√≥n de un pipeline completo para separar stems de canciones y reemplazar la voz original con modelos de IA (RVC).
*   [x] **Integraci√≥n Cloud**: Almacenamiento de modelos y resultados en Cloudflare R2.

---

## Artefactos

Se incorporaron nuevos servicios al ecosistema de Melodia:

*   **Cover Service**: Microservicio Python encargado del procesamiento de audio (separaci√≥n, conversi√≥n, mezcla).
*   **Orchestrator Service**: Servicio encargado de gestionar tareas as√≠ncronas y la comunicaci√≥n entre servicios para procesos largos.

---

## Arquitectura

La arquitectura se expandi√≥ para soportar el procesamiento intensivo de audio:

```mermaid
flowchart LR
    Client[Cliente] -->|POST /cover| Gateway[API Gateway]
    Gateway --> Orchestrator
    
    subgraph Processing [Procesamiento As√≠ncrono]
        Orchestrator -->|Schedule Task| CoverService[Cover Service]
        CoverService -->|Download| Catalog
        CoverService -->|Processing| LocalCompute[CPU/GPU]
        CoverService -->|Upload| R2[Cloudflare R2]
    end
    
    CoverService -->|Notify Completion| Users[Users Service]
```

---

## Desarrollo del Cover Service (La Traves√≠a)

A continuaci√≥n, documentamos el proceso de desarrollo de este servicio, que present√≥ desaf√≠os t√©cnicos significativos.

### üéØ Objetivo del Proyecto

Desarrollar un servicio que permita crear covers musicales utilizando modelos de voz de artistas famosos mediante RVC (Retrieval-based Voice Conversion), separaci√≥n de stems con Demucs, y procesamiento de audio con librer√≠as especializadas.

### üöÄ Fase 1: Los Inicios Prometedores

#### Primeros Pasos (Todo iba bien... por ahora)

- **Modelos de voz**: Descargados f√°cilmente desde Hugging Face (Michael Jackson, Freddy Mercury, Gustavo Cerati, The Weeknd).
- **Testing incremental y exitoso**:
  1. ‚úÖ **Paso 1**: Publicar la canci√≥n original completa ‚Üí ‚úÖ Funcion√≥
  2. ‚úÖ **Paso 2**: Extraer y publicar solo el acapella ‚Üí ‚úÖ Funcion√≥
  3. ‚úÖ **Paso 3**: Separar stems (Demucs) y volver a juntar ‚Üí ‚úÖ Funcion√≥
  
**Estado**: Todo marchaba sobre ruedas. El pipeline b√°sico de separaci√≥n y mezcla funcionaba perfectamente.

### üí• Fase 2: El Infierno de las Dependencias

#### La Pesadilla de RVC

Cuando intentamos agregar los **modelos de conversi√≥n de voz (RVC)**, comenz√≥ el caos:

**El Efecto Cascada**:
RVC necesita `torch==2.3.1` ‚Üí `numpy<1.25` ‚Üí `fairseq` (necesita numpy>=1.21,<1.24) ‚Üí `hydra-core` ‚Üí `omegaconf` (CONFLICTO con dataclasses de Python 3.12). Adem√°s, `faiss-gpu` requiere CUDA espec√≠fico incompatible con el torch instalado.

**Resultado**: D√≠as enteros resolviendo conflictos de dependencias, solo para encontrar nuevos conflictos.

### üéÆ Fase 3: La B√∫squeda de GPU

#### Plan Original: Google Cloud Run con GPU

**Objetivo**: Deployar en GCR aprovechando los cr√©ditos gratuitos.
**Problema**: GCR NO permite usar GPU sin billing account verificado (restricci√≥n anti-fraude).
**Estado**: Plan A descartado. Sin GPU local disponible para testing.

### üî¨ Fase 4: Google Colab - La Soluci√≥n Temporal

Intentamos trabajar en Colab, pero el entorno ten√≠a conflictos masivos con las dependencias de RVC y cada reinicio requer√≠a reinstalar todo. Fue demasiado inestable.

### ‚ö° Fase 5: Lightning AI - El H√©roe Inesperado

Descubrimos Lightning AI, que fue un game-changer:
1.  **CPU S√∫per Potente**: Debugging r√°pido (contenedor levanta en 10s vs 5min local).
2.  **GPU para Testing**: NVIDIA A10/T4 disponible. Conversi√≥n en ~2 minutos.

**C√≥mo lo usamos**: Desarrollo en CPU r√°pida, Testing en GPU.

### üöÄ Fase 6: Script de Deploy en Lightning AI

Creamos `lightning_deploy.sh` que levanta el contenedor y expone el servicio v√≠a **ngrok**. Esto nos permiti√≥ tener un entorno de "producci√≥n" on-demand con GPU para demos.

### üå©Ô∏è Fase 7: De Vuelta a Google Cloud Run

#### El Problema del Startup Timeout

Al intentar deployar en GCR (CPU), el contenedor fallaba porque tardaba 15 minutos en descargar los modelos, superando el timeout default de 4 minutos.

**Soluci√≥n**: Deploy en 2 fases.
1.  Deploy "Mini" (sin modelos) para que arranque r√°pido.
2.  Configurar **Startup Probe** con timeout extendido (20 min).
3.  Deploy "Completo" (con modelos).

**Resultado**: Servicio deployado exitosamente en GCR (CPU). Tarda ~15 min en procesar una canci√≥n, pero es gratis y 24/7.

### üß™ Fase 8: El Dilema del Testing

Intentamos implementar tests automatizados con mocks, pero nos enfrentamos a los mismos problemas de dependencias (pytest importando m√≥dulos que requieren CUDA).

**Decisi√≥n**: No implementar tests automatizados unitarios para el procesamiento de audio.
**Razones**: Relaci√≥n costo-beneficio negativa (tests fr√°giles, cobertura baja), dependencias inmanejables, y el hecho de que es un servicio adicional.
**Estrategia**: Testing manual exhaustivo en Lightning AI y monitoring en producci√≥n.

---

## Decisiones T√©cnicas

### 1. Estrategia de Despliegue H√≠brida

Se decidi√≥ mantener dos entornos de despliegue con prop√≥sitos diferentes:

*   **Google Cloud Run (CPU)**: Para disponibilidad 24/7 y bajo costo. Ideal para usuarios que pueden esperar ~15 minutos por su cover.
*   **Lightning AI (GPU)**: Para demostraciones y procesamiento de alta velocidad (~2 min). Se activa bajo demanda.

### 2. Gesti√≥n de Modelos con Cloudflare R2

Debido al gran tama√±o de los modelos de voz (>400MB cada uno), se decidi√≥ no incluirlos en la imagen de Docker ni en el repositorio git. En su lugar:
*   Se almacenan en un bucket de **Cloudflare R2** (compatible con S3).
*   Se descargan al iniciar el contenedor mediante un script `init_models.py`.
*   Se implement√≥ l√≥gica de cach√© local y "force redownload" para facilitar actualizaciones.

---

## Tecnolog√≠as Empleadas

*   **RVC (Retrieval-based Voice Conversion)**: Core de la clonaci√≥n de voz.
*   **Demucs**: Separaci√≥n de pistas de audio.
*   **FFmpeg**: Procesamiento y mezcla.
*   **Cloudflare R2**: Almacenamiento de objetos (modelos y resultados).
*   **Lightning AI**: Infraestructura de GPU on-demand.
*   **Google Cloud Run**: Hosting serverless.
*   **Docker**: Estandarizaci√≥n del entorno complejo.
